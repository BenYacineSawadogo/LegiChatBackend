# ğŸ¤– Claude Brief - LegiChat Integration

**Purpose**: This file helps Claude AI understand how to integrate the Angular frontend with the Flask backend in seconds.

---

## ğŸ¯ Core Facts

- **Backend**: Flask on `http://localhost:5000`
- **Frontend**: Angular 20 on `http://localhost:4200`
- **Endpoint**: `POST /api/chat`
- **Data Flow**: Frontend generates `conversationId` â†’ Backend maintains conversation context

---

## ğŸ“¡ The One Endpoint You Need

```
POST http://localhost:5000/api/chat
Content-Type: application/json

{
  "conversationId": "conv-{timestamp}-{random}",  // Frontend generates
  "message": "User question here"
}

â†’ Returns:
{
  "id": "msg-{timestamp}-{random}",              // Backend generates
  "conversationId": "conv-...",                  // Same as request
  "content": "AI response text (may contain HTML links)",
  "role": "assistant",
  "timestamp": "2025-10-22T14:30:01.000Z"       // ISO 8601
}
```

**That's it. One endpoint. JSON in, JSON out.**

---

## âš¡ 3-Step Integration

### Step 1: Frontend Config
```typescript
// src/app/core/services/chat-api.service.ts
private apiUrl = 'http://localhost:5000/api';
```

### Step 2: Send Message
```typescript
this.http.post<ChatResponse>(`${this.apiUrl}/chat`, {
  conversationId: conversationId,
  message: userMessage
}).subscribe(response => {
  // response.content contains AI answer
  displayMessage(response);
});
```

### Step 3: Handle Context
**Key**: Use the SAME `conversationId` for all messages in a conversation.
Backend automatically maintains context.

---

## ğŸ§  Backend Intelligence

The backend does 3 things automatically based on message content:

1. **Document Search**: Message like "cherche loi 2023-15" â†’ Returns PDF link
2. **Summarization**: User says "oui" after receiving PDF â†’ Returns summary
3. **Legal Q&A** (default): Any question â†’ RAG with FAISS + Mistral AI

**You don't choose the mode. Backend detects it automatically.**

---

## ğŸ”§ How It Works Behind the Scenes

```
User message â†’ Backend detects type â†’
                â”œâ”€ "cherche loi X" â†’ Search metadata â†’ Return PDF link
                â”œâ”€ "oui"/"rÃ©sume" after PDF â†’ Extract PDF â†’ Mistral summarize
                â””â”€ Normal question â†’ FAISS search â†’ Top 10 articles â†’ Mistral with context

Backend stores conversation history by conversationId:
conversations_history["conv-123"] = [
  {"role": "user", "content": "Message 1"},
  {"role": "assistant", "content": "Response 1"},
  {"role": "user", "content": "Message 2"},
  ...
]
```

---

## ğŸš€ Start Both Servers

```bash
# Terminal 1 - Backend
cd LegiChatBackend
python app.py
# â†’ http://localhost:5000

# Terminal 2 - Frontend
cd LegiChatUI
npm start
# â†’ http://localhost:4200
```

---

## ğŸ§ª Test Before Connecting Frontend

```bash
curl -X POST http://localhost:5000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"conversationId":"test-1","message":"Bonjour"}'

# Should return: {"id":"msg-...","conversationId":"test-1","content":"Bonjour ! ...","role":"assistant","timestamp":"..."}
```

---

## âš ï¸ Common Mistakes

| Mistake | Fix |
|---------|-----|
| Different `conversationId` each time | Use SAME ID for entire conversation |
| CORS error | Backend must run on port 5000, frontend on 4200 |
| 500 error | Check Mistral API key is valid |
| No context | Verify same conversationId being sent |

---

## ğŸ¨ Frontend Implementation Pattern

```typescript
export class ChatService {
  private apiUrl = 'http://localhost:5000/api';

  sendMessage(conversationId: string, message: string): Observable<Message> {
    return this.http.post<ChatResponse>(`${this.apiUrl}/chat`, {
      conversationId,
      message
    }).pipe(
      map(res => ({
        id: res.id,
        conversationId: res.conversationId,
        content: res.content,
        role: 'assistant',
        timestamp: new Date(res.timestamp)
      }))
    );
  }
}

// Usage
this.chatService.sendMessage(this.currentConversationId, userInput)
  .subscribe({
    next: (msg) => this.displayMessage(msg),
    error: (err) => this.handleError(err)
  });
```

---

## ğŸ“‹ Checklist for Claude

When helping integrate frontend â†” backend:

- [ ] Verify `apiUrl` points to `http://localhost:5000/api`
- [ ] Ensure `conversationId` is generated ONCE per conversation
- [ ] Check same `conversationId` used for follow-up messages
- [ ] Confirm request body has both `conversationId` and `message`
- [ ] Parse `response.content` for display (may contain HTML)
- [ ] Convert `response.timestamp` string to Date object
- [ ] Handle errors (400 for validation, 500 for server errors)
- [ ] Test with curl first before blaming frontend

---

## ğŸ” Debug Workflow

```
Issue: Frontend not receiving response
  â”œâ”€ Is backend running? â†’ curl http://localhost:5000/
  â”œâ”€ Is endpoint working? â†’ curl -X POST http://localhost:5000/api/chat ...
  â”œâ”€ CORS configured? â†’ Check browser console for CORS error
  â””â”€ Network tab shows request? â†’ Check Status Code (200/400/500)

Issue: No conversation context
  â””â”€ Are you sending different conversationId?
     â†’ Print conversationId in both messages, verify they match

Issue: 500 Internal Server Error
  â””â”€ Check backend terminal logs
     â†’ Usually Mistral API key issue or FAISS files missing
```

---

## ğŸ“¦ File Structure Reference

```
LegiChatBackend/
â”œâ”€â”€ app.py                    â† Main backend (line 297: /api/chat endpoint)
â”œâ”€â”€ faiss_index/              â† Embeddings & search index
â”‚   â”œâ”€â”€ embeddings.npy
â”‚   â”œâ”€â”€ index.faiss
â”‚   â”œâ”€â”€ fichier.csv
â”‚   â””â”€â”€ metadatas.pkl
â”œâ”€â”€ static/pdfs/              â† Legal documents PDFs
â”œâ”€â”€ requirements.txt          â† Dependencies (includes flask-cors)
â”œâ”€â”€ .env.example              â† Config template
â”œâ”€â”€ BACKEND_API_REFERENCE.md  â† Detailed API docs
â””â”€â”€ INTEGRATION.md            â† Full setup guide

LegiChatUI/
â””â”€â”€ src/app/core/
    â”œâ”€â”€ services/
    â”‚   â””â”€â”€ chat-api.service.ts    â† Configure apiUrl here
    â”œâ”€â”€ models/
    â”‚   â””â”€â”€ message.model.ts       â† Message interface
    â””â”€â”€ interfaces/
        â””â”€â”€ chat-api.interface.ts  â† ChatResponse interface
```

---

## ğŸ’¡ Key Insight for Claude

The frontend Angular app already has:
âœ… Conversation management (LocalStorage)
âœ… Message display logic
âœ… conversationId generation
âœ… HTTP service skeleton

**All it needs is:**
1. Change `apiUrl` to backend URL
2. Uncomment the real HTTP code
3. Comment out the mock code

**The backend already handles:**
âœ… Conversation context (by conversationId)
âœ… RAG with FAISS
âœ… Mistral AI integration
âœ… Document search & summarization
âœ… CORS configuration

**They're ready to connect. Just wire them up.**

---

## ğŸ¯ Success Criteria

Integration is successful when:
1. User sends message in Angular UI
2. Network tab shows POST to `http://localhost:5000/api/chat` with 200 status
3. Response appears in chat UI
4. Follow-up question gets contextual answer (proves conversation memory works)
5. No CORS errors in browser console

---

## ğŸ“ Quick Reference

```typescript
// Request format
interface Request {
  conversationId: string;  // e.g., "conv-1729459200-abc123"
  message: string;         // e.g., "Quelle est la procÃ©dure..."
}

// Response format
interface Response {
  id: string;              // e.g., "msg-1729459201-xyz789"
  conversationId: string;  // same as request
  content: string;         // AI answer
  role: "assistant";       // always "assistant"
  timestamp: string;       // e.g., "2025-10-22T14:30:01.000Z"
}

// Error format
interface Error {
  error: string;           // e.g., "message is required"
  details?: string;        // only in debug mode
}
```

---

## ğŸš¦ Status

- Backend: âœ… Ready (port 5000)
- CORS: âœ… Configured for localhost:4200
- Endpoint: âœ… `/api/chat` functional
- Context: âœ… Conversation history works
- Frontend: â³ Needs `apiUrl` configuration

**Next Action**: Configure frontend `apiUrl` and test.

---

**This brief is optimized for Claude AI to quickly understand the entire integration in under 60 seconds.**

For humans: See `BACKEND_API_REFERENCE.md` (detailed) or `INTEGRATION.md` (comprehensive).
